{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#üî¢ Week 4 Assignment: The \"AI Eye\" for Handwritten Digits\n",
        "Welcome to your Week 4 Assignment! üöÄ\n",
        "\n",
        "Last week, we saw how Neural Networks can bend to fit complex data. Today, we are going to apply that to Images. We'll start with a \"Standard\" Neural Network (ANN) and then upgrade it to a Convolutional Neural Network (CNN) to see why CNNs are the undisputed kings of Computer Vision.\n",
        "\n",
        "## üõ†Ô∏è Step 0: Tooling Up\n",
        "Let's import our libraries."
      ],
      "metadata": {
        "id": "HLG4kh2oT4m0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EXUdD6S4T2zv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92e9084e-477c-4c1a-a6d2-2805dfebf12d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Libraries imported!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(\"‚úÖ Libraries imported!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìÇ Step 1: Loading the MNIST Dataset\n",
        "\n",
        "The MNIST dataset consists of 70,000 small images of digits (0-9) handwritten by high school students and employees of the United States Census Bureau."
      ],
      "metadata": {
        "id": "PqdH9x_SUJsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Load the data from keras datasets\n",
        "(X_train, y_train) , (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Check the shapes\n",
        "print(f\"Training images: {X_train.shape}\")\n",
        "print(f\"Testing images: {X_test.shape}\")\n",
        "\n",
        "# Let's look at one!\n",
        "plt.matshow(X_train[0])\n",
        "plt.title(f\"Label: {y_train[0]}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bF0Jta0iUL4S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "bac5b038-7972-41cf-a0fd-90dc4388f616"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training images: (60000, 28, 28)\n",
            "Testing images: (10000, 28, 28)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üßπ Step 2: Normalization\n",
        "\n",
        "Remember from last week: AI likes numbers between 0 and 1. Currently, our pixels are 0-255.\n",
        "\n",
        "###üìù Your Task:\n",
        "\n",
        "Divide the datasets by 255."
      ],
      "metadata": {
        "id": "zB6cM2RtUXKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Normalize X_train and X_test\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "print(\"‚úÖ Data Normalized!\")"
      ],
      "metadata": {
        "id": "700rnIa6UbTa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca104bfe-7af8-4b07-9923-60628a3f27ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data Normalized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üèóÔ∏è Step 3: The Baseline (ANN)\n",
        "\n",
        "First, let's try a standard Artificial Neural Network. Since ANNs take 1D lists as input, we have to \"Flatten\" our 28x28 image into a single list of 784 pixels.\n",
        "\n",
        "###üìù Your Task:\n",
        "\n",
        "Build a Sequential model with a Flatten layer, one Hidden layer (100 neurons), and one Output layer (10 neurons)."
      ],
      "metadata": {
        "id": "swmnWD-bUu4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Complete the ANN structure\n",
        "ann_model = keras.Sequential([\n",
        "    # Flatten the 28x28 image into a 1D vector\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "\n",
        "    # Hidden layer with 100 neurons\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "\n",
        "    # Output layer with 10 neurons (one for each digit 0-9)\n",
        "    keras.layers.Dense(10, activation='softmax') # Using softmax for multi-class classification\n",
        "])\n",
        "\n",
        "### Compile the model using adam optimizer,sparse_categorical_crossentropy, and use accuracy matrix\n",
        "ann_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "### Train for 5 epochs and evaluate\n",
        "print(\"Training ANN...\")\n",
        "ann_model.fit(X_train, y_train, epochs=5)\n",
        "\n",
        "print(\"\\nANN Test Evaluation:\")\n",
        "ann_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "saGM8GcAUz8l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0df821f0-4bcb-4fdb-8ea5-b49b315169da"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ANN...\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8671 - loss: 0.4625\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.1329\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9744 - loss: 0.0895\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9808 - loss: 0.0638\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.0520\n",
            "\n",
            "ANN Test Evaluation:\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9703 - loss: 0.0925\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08161071687936783, 0.9739999771118164]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üëÅÔ∏è Step 4: The Upgrade (CNN)\n",
        "\n",
        "ANNs are okay, but they \"forget\" the shape of the digit because they flatten it. A CNN looks at the image in 2D, searching for edges and curves.\n",
        "\n",
        "**Important**: For a CNN, we need to tell it that there is 1 color channel (Grayscale). We need to reshape our data to (28, 28, 1)."
      ],
      "metadata": {
        "id": "OpQX55uFVVmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping for the CNN\n",
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "print(f\"New Shape: {X_train.shape}\")"
      ],
      "metadata": {
        "id": "HkZMLBSCVftF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üìù Your Task:\n",
        "\n",
        "Build the CNN. Use a Conv2D layer to find features and a MaxPooling2D layer to summarize them."
      ],
      "metadata": {
        "id": "sStmjf6zViXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Complete the CNN structure\n",
        "cnn_model = keras.Sequential([\n",
        "    # 1. Convolutional Layer (The Filter)\n",
        "    # Hint: Use 30 filters, kernel size (3,3)\n",
        "    layers.Conv2D(filters=30, kernel_size=(3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "\n",
        "    # 2. Pooling Layer (The Zoom Out)\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    # 3. Dense Layers (The Decision)\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(100, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train for 5 epochs\n",
        "print(\"Training CNN...\")\n",
        "cnn_model.fit(X_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate\n",
        "print(\"\\nCNN Test Evaluation:\")\n",
        "cnn_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "s63y2-aWVmhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c1c7c54-3dee-4b4e-8e92-b0415f44f9e3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training CNN...\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 19ms/step - accuracy: 0.9054 - loss: 0.3145\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 19ms/step - accuracy: 0.9831 - loss: 0.0549\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 19ms/step - accuracy: 0.9895 - loss: 0.0340\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 18ms/step - accuracy: 0.9932 - loss: 0.0219\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 19ms/step - accuracy: 0.9956 - loss: 0.0154\n",
            "\n",
            "CNN Test Evaluation:\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9833 - loss: 0.0489\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04103080555796623, 0.9871000051498413]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Step 5: Final Analysis\n",
        "\n",
        "Check your results!\n",
        "\n",
        "**Submission**: Save this notebook and submit your Google Colab link via the Assignment 4 Form!\n",
        "\n",
        "*Created with ‚ù§Ô∏è for WiDS Project*"
      ],
      "metadata": {
        "id": "x9Dm3kIRVrzl"
      }
    }
  ]
}